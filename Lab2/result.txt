Learning Rate: 5e-05
              precision    recall  f1-score   support

           0       1.00      0.87      0.93       250
           1       0.88      1.00      0.94       250

    accuracy                           0.93       500
   macro avg       0.94      0.93      0.93       500
weighted avg       0.94      0.93      0.93       500


Epoch-wise Losses:
Epoch=1, loss=23.030886638717345
Epoch=2, loss=23.03066521299418
Epoch=3, loss=23.030443791958312
Epoch=4, loss=23.03022237560959
Epoch=5, loss=23.030000963947884
Epoch=6, loss=23.029779556973068
Epoch=7, loss=23.02955815468499
Epoch=8, loss=23.029336757083524
Epoch=9, loss=23.02911536416852
Epoch=10, loss=23.02889397593986
Epoch=11, loss=23.028672592397378
Epoch=12, loss=23.02845121354097
Epoch=13, loss=23.028229839370482
Epoch=14, loss=23.02800846988577
Epoch=15, loss=23.027787105086716
Epoch=16, loss=23.027565744973167
Epoch=17, loss=23.027344389544982
Epoch=18, loss=23.027123038802042
Epoch=19, loss=23.026901692744197
Epoch=20, loss=23.02668035137131
Epoch=21, loss=23.02645901468325
Epoch=22, loss=23.026237682679877
Epoch=23, loss=23.026016355361065
Epoch=24, loss=23.025795032726663
Epoch=25, loss=23.025573714776538
Epoch=26, loss=23.025352401510553
Epoch=27, loss=23.02513109292857
Epoch=28, loss=23.024909789030445
Epoch=29, loss=23.024688489816064
Epoch=30, loss=23.02446719528527
Epoch=31, loss=23.02424590543792
Epoch=32, loss=23.02402462027389
Epoch=33, loss=23.023803339793044
Epoch=34, loss=23.02358206399525
Epoch=35, loss=23.023360792880354
Epoch=36, loss=23.02313952644824
Epoch=37, loss=23.022918264698752
Epoch=38, loss=23.022697007631763
Epoch=39, loss=23.02247575524713
Epoch=40, loss=23.022254507544726
Epoch=41, loss=23.022033264524403
Epoch=42, loss=23.021812026186026
Epoch=43, loss=23.021590792529462
Epoch=44, loss=23.021369563554572
Epoch=45, loss=23.02114833926122
Epoch=46, loss=23.020927119649265
Epoch=47, loss=23.020705904718586
Epoch=48, loss=23.02048469446902
Epoch=49, loss=23.020263488900444
Epoch=50, loss=23.020042288012732
Epoch=51, loss=23.019821091805728
Epoch=52, loss=23.019599900279307
Epoch=53, loss=23.01937871343333
Epoch=54, loss=23.019157531267666
Epoch=55, loss=23.018936353782166
Epoch=56, loss=23.01871518097669
Epoch=57, loss=23.018494012851114
Epoch=58, loss=23.01827284940531
Epoch=59, loss=23.01805169063912
Epoch=60, loss=23.01783053655241
Epoch=61, loss=23.017609387145043
Epoch=62, loss=23.017388242416896
Epoch=63, loss=23.01716710236782
Epoch=64, loss=23.01694596699769
Epoch=65, loss=23.01672483630636
Epoch=66, loss=23.016503710293694
Epoch=67, loss=23.016282588959548
Epoch=68, loss=23.016061472303793
Epoch=69, loss=23.015840360326294
Epoch=70, loss=23.015619253026916
Epoch=71, loss=23.015398150405513
Epoch=72, loss=23.015177052461954
Epoch=73, loss=23.0149559591961
Epoch=74, loss=23.014734870607825
Epoch=75, loss=23.014513786696984
Epoch=76, loss=23.014292707463426
Epoch=77, loss=23.01407163290704
Epoch=78, loss=23.013850563027674
Epoch=79, loss=23.013629497825193
Epoch=80, loss=23.013408437299454
Epoch=81, loss=23.013187381450336
Epoch=82, loss=23.012966330277685
Epoch=83, loss=23.012745283781385
Epoch=84, loss=23.01252424196128
Epoch=85, loss=23.012303204817243
Epoch=86, loss=23.01208217234914
Epoch=87, loss=23.011861144556832
Epoch=88, loss=23.011640121440173
Epoch=89, loss=23.011419102999035
Epoch=90, loss=23.011198089233275
Epoch=91, loss=23.01097708014277
Epoch=92, loss=23.010756075727368
Epoch=93, loss=23.010535075986937
Epoch=94, loss=23.010314080921344
Epoch=95, loss=23.010093090530447
Epoch=96, loss=23.00987210481412
Epoch=97, loss=23.009651123772215
Epoch=98, loss=23.009430147404597
Epoch=99, loss=23.009209175711128
Epoch=100, loss=23.008988208691683

Learning Rate: 0.005
              precision    recall  f1-score   support

           0       1.00      0.88      0.94       250
           1       0.89      1.00      0.94       250

    accuracy                           0.94       500
   macro avg       0.95      0.94      0.94       500
weighted avg       0.95      0.94      0.94       500


Epoch-wise Losses:
Epoch=1, loss=23.008767246346114
Epoch=2, loss=22.986683043509156
Epoch=3, loss=22.96464550019244
Epoch=4, loss=22.942654480180213
Epoch=5, loss=22.92070984771933
Epoch=6, loss=22.89881146751764
Epoch=7, loss=22.876959204742455
Epoch=8, loss=22.855152925018906
Epoch=9, loss=22.833392494428367
Epoch=10, loss=22.81167777950688
Epoch=11, loss=22.79000864724359
Epoch=12, loss=22.76838496507916
Epoch=13, loss=22.746806600904176
Epoch=14, loss=22.725273423057647
Epoch=15, loss=22.70378530032537
Epoch=16, loss=22.682342101938445
Epoch=17, loss=22.660943697571653
Epoch=18, loss=22.639589957341954
Epoch=19, loss=22.618280751806946
Epoch=20, loss=22.59701595196329
Epoch=21, loss=22.57579542924521
Epoch=22, loss=22.55461905552296
Epoch=23, loss=22.53348670310124
Epoch=24, loss=22.512398244717765
Epoch=25, loss=22.491353553541682
Epoch=26, loss=22.470352503172084
Epoch=27, loss=22.449394967636472
Epoch=28, loss=22.428480821389293
Epoch=29, loss=22.407609939310397
Epoch=30, loss=22.386782196703567
Epoch=31, loss=22.36599746929501
Epoch=32, loss=22.345255633231893
Epoch=33, loss=22.32455656508084
Epoch=34, loss=22.303900141826446
Epoch=35, loss=22.283286240869806
Epoch=36, loss=22.262714740027064
Epoch=37, loss=22.242185517527943
Epoch=38, loss=22.221698452014248
Epoch=39, loss=22.20125342253844
Epoch=40, loss=22.180850308562178
Epoch=41, loss=22.160488989954878
Epoch=42, loss=22.14016934699224
Epoch=43, loss=22.11989126035484
Epoch=44, loss=22.099654611126674
Epoch=45, loss=22.07945928079372
Epoch=46, loss=22.05930515124254
Epoch=47, loss=22.039192104758826
Epoch=48, loss=22.019120024025998
Epoch=49, loss=21.9990887921238
Epoch=50, loss=21.97909829252685
Epoch=51, loss=21.95914840910327
Epoch=52, loss=21.9392390261133
Epoch=53, loss=21.919370028207844
Epoch=54, loss=21.899541300427117
Epoch=55, loss=21.879752728199268
Epoch=56, loss=21.860004197338963
Epoch=57, loss=21.840295594045998
Epoch=58, loss=21.820626804903988
Epoch=59, loss=21.800997716878932
Epoch=60, loss=21.781408217317864
Epoch=61, loss=21.761858193947507
Epoch=62, loss=21.742347534872906
Epoch=63, loss=21.72287612857605
Epoch=64, loss=21.703443863914558
Epoch=65, loss=21.68405063012032
Epoch=66, loss=21.66469631679817
Epoch=67, loss=21.6453808139245
Epoch=68, loss=21.626104011846003
Epoch=69, loss=21.606865801278293
Epoch=70, loss=21.587666073304575
Epoch=71, loss=21.56850471937438
Epoch=72, loss=21.549381631302197
Epoch=73, loss=21.530296701266177
Epoch=74, loss=21.511249821806846
Epoch=75, loss=21.49224088582578
Epoch=76, loss=21.473269786584318
Epoch=77, loss=21.454336417702265
Epoch=78, loss=21.435440673156602
Epoch=79, loss=21.4165824472802
Epoch=80, loss=21.397761634760556
Epoch=81, loss=21.378978130638487
Epoch=82, loss=21.360231830306883
Epoch=83, loss=21.341522629509445
Epoch=84, loss=21.322850424339368
Epoch=85, loss=21.30421511123814
Epoch=86, loss=21.28561658699428
Epoch=87, loss=21.26705474874204
Epoch=88, loss=21.248529493960227
Epoch=89, loss=21.230040720470896
Epoch=90, loss=21.21158832643816
Epoch=91, loss=21.193172210366928
Epoch=92, loss=21.174792271101676
Epoch=93, loss=21.156448407825227
Epoch=94, loss=21.13814052005754
Epoch=95, loss=21.11986850765448
Epoch=96, loss=21.101632270806597
Epoch=97, loss=21.083431710037924
Epoch=98, loss=21.0652667262048
Epoch=99, loss=21.0471372204946
Epoch=100, loss=21.029043094424622

Learning Rate: 0.05
              precision    recall  f1-score   support

           0       1.00      0.95      0.97       250
           1       0.95      1.00      0.97       250

    accuracy                           0.97       500
   macro avg       0.98      0.97      0.97       500
weighted avg       0.98      0.97      0.97       500


Epoch-wise Losses:
Epoch=1, loss=21.010984249840824
Epoch=2, loss=20.83153602733659
Epoch=3, loss=20.655546747527357
Epoch=4, loss=20.48292185597034
Epoch=5, loss=20.313569909810134
Epoch=6, loss=20.147402465864804
Epoch=7, loss=19.984333972671905
Epoch=8, loss=19.82428166639063
Epoch=9, loss=19.667165470453305
Epoch=10, loss=19.512907898857605
Epoch=11, loss=19.36143396298995
Epoch=12, loss=19.212671081870248
Epoch=13, loss=19.06654899570836
Epoch=14, loss=18.922999682663665
Epoch=15, loss=18.781957278700368
Epoch=16, loss=18.64335800043265
Epoch=17, loss=18.507140070855865
Epoch=18, loss=18.373243647861894
Epoch=19, loss=18.241610755439332
Epoch=20, loss=18.11218521746137
Epoch=21, loss=17.984912593967017
Epoch=22, loss=17.859740119843757
Epoch=23, loss=17.73661664582248
Epoch=24, loss=17.61549258169832
Epoch=25, loss=17.496319841693474
Epoch=26, loss=17.379051791881185
Epoch=27, loss=17.263643199592295
Epoch=28, loss=17.150050184728876
Epoch=29, loss=17.038230172911632
Epoch=30, loss=16.928141850390737
Epoch=31, loss=16.819745120651984
Epoch=32, loss=16.713001062652687
Epoch=33, loss=16.607871890624228
Epoch=34, loss=16.50432091538046
Epoch=35, loss=16.40231250707326
Epoch=36, loss=16.301812059339138
Epoch=37, loss=16.202785954782406
Epoch=38, loss=16.10520153174303
Epoch=39, loss=16.009027052298862
Epoch=40, loss=15.914231671454152
Epoch=41, loss=15.820785407467964
Epoch=42, loss=15.728659113278
Epoch=43, loss=15.637824448977081
Epoch=44, loss=15.548253855301152
Epoch=45, loss=15.459920528089398
Epoch=46, loss=15.372798393678492
Epoch=47, loss=15.286862085194642
Epoch=48, loss=15.202086919708377
Epoch=49, loss=15.118448876218668
Epoch=50, loss=15.035924574433928
Epoch=51, loss=14.954491254319159
Epoch=52, loss=14.87412675637938
Epoch=53, loss=14.794809502650928
Epoch=54, loss=14.71651847837315
Epoch=55, loss=14.639233214314327
Epoch=56, loss=14.562933769726467
Epoch=57, loss=14.487600715904836
Epoch=58, loss=14.413215120328978
Epoch=59, loss=14.339758531362882
Epoch=60, loss=14.267212963492833
Epoch=61, loss=14.195560883082553
Epoch=62, loss=14.124785194625645
Epoch=63, loss=14.054869227476626
Epoch=64, loss=13.985796723042231
Epoch=65, loss=13.917551822415541
Epoch=66, loss=13.85011905443623
Epoch=67, loss=13.78348332416077
Epoch=68, loss=13.717629901727193
Epoch=69, loss=13.652544411599536
Epoch=70, loss=13.588212822177791
Epoch=71, loss=13.52462143575959
Epoch=72, loss=13.461756878840585
Epoch=73, loss=13.399606092740846
Epoch=74, loss=13.338156324545206
Epoch=75, loss=13.277395118345899
Epoch=76, loss=13.217310306776337
Epoch=77, loss=13.15789000282527
Epoch=78, loss=13.099122591921063
Epoch=79, loss=13.040996724276114
Epoch=80, loss=12.983501307482047
Epoch=81, loss=12.926625499346322
Epoch=82, loss=12.870358700961685
Epoch=83, loss=12.81469054999992
Epoch=84, loss=12.75961091422179
Epoch=85, loss=12.705109885195432
Epoch=86, loss=12.651177772215647
Epoch=87, loss=12.597805096416913
Epoch=88, loss=12.544982585073258
Epoch=89, loss=12.492701166078216
Epoch=90, loss=12.4409519625986
Epoch=91, loss=12.389726287895853
Epoch=92, loss=12.339015640309078
Epoch=93, loss=12.288811698394124
Epoch=94, loss=12.239106316213148
Epoch=95, loss=12.189891518769485
Epoch=96, loss=12.141159497582736
Epoch=97, loss=12.092902606399168
Epoch=98, loss=12.045113357032793
Epoch=99, loss=11.997784415332598
Epoch=100, loss=11.950908597271582

Learning Rate: 0.5
              precision    recall  f1-score   support

           0       1.00      0.98      0.99       250
           1       0.98      1.00      0.99       250

    accuracy                           0.99       500
   macro avg       0.99      0.99      0.99       500
weighted avg       0.99      0.99      0.99       500


Epoch-wise Losses:
Epoch=1, loss=11.90447886515344
Epoch=2, loss=11.454188249933527
Epoch=3, loss=11.043771862663
Epoch=4, loss=10.667648074458127
Epoch=5, loss=10.321221124723706
Epoch=6, loss=10.000673589304881
Epoch=7, loss=9.702809406068344
Epoch=8, loss=9.42493363026025
Epoch=9, loss=9.164759230530235
Epoch=10, loss=8.920334046792355
Epoch=11, loss=8.68998296306685
Epoch=12, loss=8.47226169308816
Epoch=13, loss=8.265919523852768
Epoch=14, loss=8.069869037875417
Epoch=15, loss=7.883161322412735
Epoch=16, loss=7.7049655297219015
Epoch=17, loss=7.53455191500106
Epoch=18, loss=7.371277674493472
Epoch=19, loss=7.2145750537707745
Epoch=20, loss=7.063941308417088
Epoch=21, loss=6.9189301854405905
Epoch=22, loss=6.779144660368653
Epoch=23, loss=6.644230716942809
Epoch=24, loss=6.513871997141521
Epoch=25, loss=6.3877851815241256
Epoch=26, loss=6.265715985550498
Epoch=27, loss=6.147435678049018
Epoch=28, loss=6.032738044489962
Epoch=29, loss=5.921436731021716
Epoch=30, loss=5.813362915998782
Epoch=31, loss=5.70836326448351
Epoch=32, loss=5.60629812833756
Epoch=33, loss=5.507039960350306
Epoch=34, loss=5.410471915630648
Epoch=35, loss=5.316486617417174
Epoch=36, loss=5.224985067700613
Epoch=37, loss=5.13587568573297
Epoch=38, loss=5.049073459725045
Epoch=39, loss=4.964499198894263
Epoch=40, loss=4.88207887458762
Epoch=41, loss=4.80174304052638
Epoch=42, loss=4.723426323346025
Epoch=43, loss=4.647066975573453
Epoch=44, loss=4.57260648402325
Epoch=45, loss=4.499989227329737
Epoch=46, loss=4.42916217697992
Epoch=47, loss=4.360074636789397
Epoch=48, loss=4.292678016280121
Epoch=49, loss=4.226925633884745
Epoch=50, loss=4.162772546324102
Epoch=51, loss=4.1001754008874745
Epoch=52, loss=4.039092307694194
Epoch=53, loss=3.9794827293328394
Epoch=54, loss=3.9213073855638623
Epoch=55, loss=3.8645281710347987
Epoch=56, loss=3.8091080841965628
Epoch=57, loss=3.7550111658259957
Epoch=58, loss=3.702202445755775
Epoch=59, loss=3.6506478965889864
Epoch=60, loss=3.6003143933339734
Epoch=61, loss=3.551169678036365
Epoch=62, loss=3.5031823286111345
Epoch=63, loss=3.456321731189079
Epoch=64, loss=3.410558055390715
Epoch=65, loss=3.3658622320271903
Epoch=66, loss=3.3222059328037417
Epoch=67, loss=3.2795615516673693
Epoch=68, loss=3.237902187497861
Epoch=69, loss=3.1972016278909874
Epoch=70, loss=3.1574343338254476
Epoch=71, loss=3.1185754250418043
Epoch=72, loss=3.080600665992927
Epoch=73, loss=3.043486452252045
Epoch=74, loss=3.007209797286964
Epoch=75, loss=2.9717483195278946
Epoch=76, loss=2.937080229672164
Epoch=77, loss=2.9031843181822063
Epoch=78, loss=2.8700399429441386
Epoch=79, loss=2.837627017063111
Epoch=80, loss=2.8059259967789245
Epoch=81, loss=2.7749178694912606
Epoch=82, loss=2.7445841418885326
Epoch=83, loss=2.7149068281780893
Epoch=84, loss=2.68586843841835
Epoch=85, loss=2.6574519669555885
Epoch=86, loss=2.629640880969725
Epoch=87, loss=2.602419109134572
Epoch=88, loss=2.575771030398755
Epoch=89, loss=2.549681462893932
Epoch=90, loss=2.524135652977141
Epoch=91, loss=2.4991192644140794
Epoch=92, loss=2.474618367709944
Epoch=93, loss=2.450619429594194
Epoch=94, loss=2.427109302665186
Epoch=95, loss=2.404075215200211
Epoch=96, loss=2.3815047611359708
Epoch=97, loss=2.3593858902240092
Epoch=98, loss=2.3377068983650653
Epoch=99, loss=2.316456418125826
Epoch=100, loss=2.2956234094409504

Learning Rate: 5
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       250
           1       1.00      1.00      1.00       250

    accuracy                           1.00       500
   macro avg       1.00      1.00      1.00       500
weighted avg       1.00      1.00      1.00       500


Epoch-wise Losses:
Epoch=1, loss=2.2751971505027853
Epoch=2, loss=2.0835153514231743
Epoch=3, loss=1.9257548862259515
Epoch=4, loss=1.7941638199154224
Epoch=5, loss=1.6830408274408701
Epoch=6, loss=1.588160450072186
Epoch=7, loss=1.506360503480568
Epoch=8, loss=1.4352485231009915
Epoch=9, loss=1.3729930781207518
Epoch=10, loss=1.3181747218344932
Epoch=11, loss=1.269678650734582
Epoch=12, loss=1.226616606246407
Epoch=13, loss=1.188269456319695
Epoch=14, loss=1.1540446168404856
Epoch=15, loss=1.1234443423332854
Epoch=16, loss=1.0960421776732587
Epoch=17, loss=1.071465692446524
Epoch=18, loss=1.0493841418958807
Epoch=19, loss=1.0295000068474325
Epoch=20, loss=1.0115435355001619
Epoch=21, loss=0.9952695060693666
Epoch=22, loss=0.980455501819674
Epoch=23, loss=0.9669010735233947
Epoch=24, loss=0.95442727438797
Epoch=25, loss=0.9428761866603004
Epoch=26, loss=0.9321102025734107
Epoch=27, loss=0.9220109556164906
Epoch=28, loss=0.9124779047933603
Epoch=29, loss=0.9034266456975778
Epoch=30, loss=0.894787057534898
Epoch=31, loss=0.8865014008993686
Epoch=32, loss=0.8785224666727899
Epoch=33, loss=0.8708118515664364
Epoch=34, loss=0.8633384084019189
Epoch=35, loss=0.85607689440941
Epoch=36, loss=0.8490068212300741
Epoch=37, loss=0.8421114966317417
Epoch=38, loss=0.8353772396656118
Epoch=39, loss=0.8287927470176782
Epoch=40, loss=0.8223485874199761
Epoch=41, loss=0.8160368020817514
Epoch=42, loss=0.8098505913058796
Epoch=43, loss=0.8037840701438914
Epoch=44, loss=0.7978320787024775
Epoch=45, loss=0.791990035302373
Epoch=46, loss=0.7862538229839254
Epoch=47, loss=0.7806197018083277
Epoch=48, loss=0.7750842410228647
Epoch=49, loss=0.7696442664718186
Epoch=50, loss=0.7642968196823857
Epoch=51, loss=0.7590391258801525
Epoch=52, loss=0.7538685688320929
Epoch=53, loss=0.7487826709127838
Epoch=54, loss=0.7437790771721402
Epoch=55, loss=0.7388555424756803
Epoch=56, loss=0.7340099210114182
Epoch=57, loss=0.729240157627029
Epoch=58, loss=0.724544280589528
Epoch=59, loss=0.719920395457131
Epoch=60, loss=0.7153666798266852
Epoch=61, loss=0.7108813787758758
Epoch=62, loss=0.7064628008616394
Epoch=63, loss=0.7021093145682189
Epoch=64, loss=0.6978193451225536
Epoch=65, loss=0.693591371613126
Epoch=66, loss=0.6894239243624033
Epoch=67, loss=0.6853155825137106
Epoch=68, loss=0.6812649718015424
Epoch=69, loss=0.6772707624805966
Epoch=70, loss=0.6733316673936444
Epoch=71, loss=0.6694464401620873
Epoch=72, loss=0.665613873485942
Epoch=73, loss=0.661832797542277
Epoch=74, loss=0.6581020784728934
Epoch=75, loss=0.6544206169534516
Epoch=76, loss=0.6507873468373749
Epoch=77, loss=0.6472012338687512
Epoch=78, loss=0.6436612744591912
Epoch=79, loss=0.6401664945241965
Epoch=80, loss=0.6367159483750788
Epoch=81, loss=0.6333087176628827
Epoch=82, loss=0.6299439103711154
Epoch=83, loss=0.626620659854367
Epoch=84, loss=0.6233381239201663
Epoch=85, loss=0.6200954839516324
Epoch=86, loss=0.616891944068667
Epoch=87, loss=0.613726730325612
Epoch=88, loss=0.6105990899434246
Epoch=89, loss=0.6075082905745841
Epoch=90, loss=0.6044536195990349
Epoch=91, loss=0.6014343834496018
Epoch=92, loss=0.5984499069653968
Epoch=93, loss=0.5954995327718393
Epoch=94, loss=0.5925826206859834
Epoch=95, loss=0.5896985471459304
Epoch=96, loss=0.5868467046631701
Epoch=97, loss=0.5840265012967693
Epoch=98, loss=0.581237360148371
Epoch=99, loss=0.5784787188770398
Epoch=100, loss=0.5757500292330351

Learning Rate: 15
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       250
           1       1.00      1.00      1.00       250

    accuracy                           1.00       500
   macro avg       1.00      1.00      1.00       500
weighted avg       1.00      1.00      1.00       500


Epoch-wise Losses:
Epoch=1, loss=0.573050756609641
Epoch=2, loss=0.5650822810394539
Epoch=3, loss=0.55736403629758
Epoch=4, loss=0.5498832458727371
Epoch=5, loss=0.5426280268905267
Epoch=6, loss=0.5355873116437704
Epoch=7, loss=0.5287507773598973
Epoch=8, loss=0.5221087832028432
Epoch=9, loss=0.5156523136457936
Epoch=10, loss=0.509372927468224
Epoch=11, loss=0.503262711729929
Epoch=12, loss=0.49731424015922365
Epoch=13, loss=0.4915205354646371
Epoch=14, loss=0.48587503514124963
Epoch=15, loss=0.4803715603959624
Epoch=16, loss=0.4750042878617712
Epoch=17, loss=0.46976772381069787
Epoch=18, loss=0.4646566806092992
Epoch=19, loss=0.45966625519044274
Epoch=20, loss=0.45479180934094565
Epoch=21, loss=0.4500289516272707
Epoch=22, loss=0.44537352080122994
Epoch=23, loss=0.4408215705449545
Epoch=24, loss=0.4363693554295768
Epoch=25, loss=0.43201331797544634
Epoch=26, loss=0.4277500767134542
Epoch=27, loss=0.42357641515746086
Epoch=28, loss=0.41948927160699556
Epoch=29, loss=0.41548572970755376
Epoch=30, loss=0.4115630097030388
Epoch=31, loss=0.40771846032132936
Epoch=32, loss=0.40394955123966114
Epoch=33, loss=0.40025386608162844
Epoch=34, loss=0.3966290959021545
Epoch=35, loss=0.39307303312085845
Epoch=36, loss=0.389583565867899
Epoch=37, loss=0.3861586727096424
Epoch=38, loss=0.38279641772444856
Epoch=39, loss=0.37949494590150373
Epoch=40, loss=0.3762524788380212
Epoch=41, loss=0.37306731071226573
Epoch=42, loss=0.36993780451180325
Epoch=43, loss=0.3668623884981267
Epoch=44, loss=0.3638395528903893
Epoch=45, loss=0.3608678467524218
Epoch=46, loss=0.35794587506850156
Epoch=47, loss=0.3550722959945303
Epoch=48, loss=0.35224581827235113
Epoch=49, loss=0.34946519879591126
Epoch=50, loss=0.3467292403188663
Epoch=51, loss=0.344036789294041
Epoch=52, loss=0.3413867338358909
Epoch=53, loss=0.33877800179779655
Epoch=54, loss=0.33620955895663385
Epoch=55, loss=0.3336804072976365
Epoch=56, loss=0.3311895833930768
Epoch=57, loss=0.32873615686877783
Epoch=58, loss=0.32631922895289533
Epoch=59, loss=0.323937931101816
Epoch=60, loss=0.3215914236983868
Epoch=61, loss=0.319278894818021
Epoch=62, loss=0.31699955905855326
Epoch=63, loss=0.31475265642998623
Epoch=64, loss=0.31253745130055244
Epoch=65, loss=0.3103532313957471
Epoch=66, loss=0.30819930684722135
Epoch=67, loss=0.3060750092886328
Epoch=68, loss=0.30397969099573713
Epoch=69, loss=0.30191272406819547
Epoch=70, loss=0.2998734996507238
Epoch=71, loss=0.29786142719137443
Epoch=72, loss=0.2958759337348774
Epoch=73, loss=0.29391646324910153
Epoch=74, loss=0.2919824759828185
Epoch=75, loss=0.29007344785306693
Epoch=76, loss=0.2881888698605191
Epoch=77, loss=0.286328247531351
Epoch=78, loss=0.28449110038420933
Epoch=79, loss=0.2826769614209529
Epoch=80, loss=0.2808853766399256
Epoch=81, loss=0.2791159045705956
Epoch=82, loss=0.27736811582845755
Epoch=83, loss=0.27564159268916655
Epoch=84, loss=0.2739359286809303
Epoch=85, loss=0.27225072819423846
Epoch=86, loss=0.2705856061080691
Epoch=87, loss=0.26894018743175163
Epoch=88, loss=0.26731410696172136
Epoch=89, loss=0.2657070089524367
Epoch=90, loss=0.2641185468007742
Epoch=91, loss=0.2625483827432544
Epoch=92, loss=0.26099618756548454
Epoch=93, loss=0.25946164032324215
Epoch=94, loss=0.2579444280746501
Epoch=95, loss=0.25644424562292584
Epoch=96, loss=0.25496079526921406
Epoch=97, loss=0.2534937865750413
Epoch=98, loss=0.2520429361339481
Epoch=99, loss=0.25060796735188634
Epoch=100, loss=0.24918861023598415

